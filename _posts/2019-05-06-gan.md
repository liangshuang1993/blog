### GAN papers


最近希望将GAN用于TTS上,所以学习一些GAN相关的文章.


#### Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets

这篇文章将GAN应用到了机器翻译中,这里用的是conditional sequence generative adversarial net.

和TTS类似,常见的机器翻译模型也是一个含有attention的seq2seq模型,但是这些模型通常是优化每个时间步ground word的极大似然估计,这会带来一些问题:很多时候当前的最优并不代表整个句子层面的最优,虽然后面也有一个sentence-level BLEU的提出,但是这种n-gram预测也不能保证好的结果.

本文的模型包含两个方面:一个generator基于输入的source language sentence来生成target language sentence;一个discriminator,condition on source language sentence,预测target language sentence是否是人类生成的. 除了生成想要的分布外,我们还希望可以用一个静态的特定的目标函数直接引导generator,比如生成高的BLEU分.这里使用的是smoothed sentence-level BLEU.训练的时候,用动态的discriminator和静态的BLEU目标函数来引导训练.

**模型结构: BLEU reinforced conditional sequence generative adversarial net**

可以将句子生成的过程视为根据generator产生的策略做选择的过程.采用了policy gradient.

**generator**

和NMT的模型完全一样,这里采用了RNNSearch和Transformer两种

**discriminator**
这里采用CNN结构.由于G产生的句子是不定长的,所以需要用padding.给定source language sequence $X_{1:T}=x_1; ...;x_T$, target language sequence $Y_{1:T}=y_1; ...; y_T$,其中$x_t,y_t \in R^k$.对于输入的矩阵$X_{1:T}$,用$w_j \in R^{l\times k}$记性卷积操作.得到feature map: $c_{ji}=\rho(BN(w_j X_{i:i+l-1} + b)) $.之后在用max-over-time pooling: $\tilde c_j=max{c_{j1},..., c_{jT-l+1}}$这里用的是不同大小的kernel来提取不同的特征,之后再将他们拼起来,得到$c_x$.同理,target language sequence可以得到$c_y$,最后,给定source language sequence,判断target language sequence是真的概率为$p=\sigma(V[c_x;c_y])$,V将输入转换为2维的embedding,$\sigma$是logistic函数.

**BLEU objective**

给定生成的$y_g$和ground truth $y_d$,可以计算奖励函数$Q(y_g,y_d)$,Q的取值是0到1.

**Policy gradient training**

![](/papers/tts/59.png)
其中R代表action-value函数.

![](/papers/tts/60.png)
其中,b表示baseline value,来减小reward的variance,实际上,可以将b设为常量0.5.

还有一个问题在于,给定source sequence,D通常只能在target sequence预测结束后给一个分数,因此我们不能获得一个实时的action-value.对于未知的token,这里采用了基于策略G的Monte Carlo search.采用N个采用的结果的平均值作为中间状态的reward.

一旦我们可以产生比较真实的输出,可以重新训练D:

![](/papers/tts/61.png)


更新完D之后,重新训练G:

![](/papers/tts/62.png)

首先用极大似然预训练G.之后用G产生语句,这里用greedy sampling而不是beam search.之后用true paralle data和machine产生的data来pretrain D,知道D的准确率可以达到某个值,这里用的0.82.最后,联合训练G和D,G用policy gradient来训练,不过实际上,发现用简单的policy gradient容易导致不稳定,因此这里用了teacher forcing.

**实验**

主要实验了$\lambda$和D的初始化准确率,采样个数对最终结果的影响.

----

#### Wasserstein GAN and WaveformLoss-based Acoustic Model Training forMulti-speaker Text-to-Speech SynthesisSystems Using a WaveNet Vocoder

利用了conditional GAN.

![](/papers/tts/63.png)

loss结合了MSE adversarial loss.

训练过程:

- generator预训练:用MSE训练
- adversarial training:用MSE和ADV训练
- finetune: 用wavenet loss对generator进行finetune.

----

#### SPEECH SUPER RESOLUTION GENERATIVE ADVERSARIAL NETWORK

目前也有一些GAN如improved-GAN,Cat-GAN,SGAN,Triple-GAN也是解决半监督问题,但是是用于分类问题的.这篇是目前第一篇半监督GAN用于回归问题的.

本文是基于Improved-GAN的改进.Improved-GAN的基本思想是用一个网络同时做分类和判别的作用,即输出N+1个值,前N个值进行分类,最后一个值则是代表True/False.除此之外,Improved-GAN用了feature matching来解决G的不稳定问题,传统的GAN的G努力的最大化D的输出,而这里则是最大化D中间generated的数据和真实数据的匹配程度,即最小化其差异.

这里提出了两种D的架构:

1. D有两种输出:第一种用来预测标签,第二种是预测real/fake.我们假设label可以正则化到[0, 1]范围,D用常见的非监督GAN loss和监督的regression loss:

![](/papers/tts/64.png)

z是噪声的分布,x是真实数据的分布,G(x)是生成数据的分布,y表示label的值,$\hat y$表示预测的label.不过这里的unsupervised loss实际用的是最小二乘loss.

2. 这里D只有一个输出:标签的预测值.之后将标签送入一个新的方程,基于预测的标签给input一个index.换句话说,这里没有用网络来区分真实数据和产生的数据,而是用了一个kernel function,接收regression output来判断预测出来的label是真是假.如果predicted label是在规划化的true label的范围内,比如在[0, 1]之内,那么给的index是1,否则给的index会是远小于1的值,根据相距的距离.

![](/papers/tts/65.png)

