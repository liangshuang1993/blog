### Convolutional Networks for NLP


这节课老师推荐了一本书*Natural Language Processing with PyTorch*

前面讲到的模型通常都是使用了RNN，但是RNN也存在一些问题，比如:
- cannot capture phrases without prefix context.
- often capture too much of last words in final vector

因此，这里就引入了CNN，直观来讲:
> what if we compute vectors for every possible word subsequence of a certain length?

卷积的概念可以参考cs231的内容，本文就不介绍了。
在文本的处理上，通常用的是1D卷积：

![](courses/cs224/images/lecture11/1.png)

和图像相似，这里的卷积也可以使用padding，可以有多个channel，可以有pooling

![](courses/cs224/images/lecture11/2.png)

PyTorch实现起来也很简单：

```python
batch_size = 16
word_embed_size = 4
seq_len = 7
input = torch.randn(batch_size, word_embed_size, seq_len)
conv1 = Conv1d(in_channels=word_embed_size, out_channels=3, kernel_size=3) # can add: padding=1
hidden1 = conv1(input)
hidden2 = torch.max(hidden1, dim=2) # max pool
```

也可以使用空洞卷积(dilation)，可以增大感知野
![](https://pic2.zhimg.com/50/v2-4959201e816888c6648f2e78cccfd253_hd.gif)

__Single Layer CNN for Sentence Classification__

