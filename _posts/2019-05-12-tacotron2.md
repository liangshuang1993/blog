今天再来整理下tacotron2模型结构。


论文地址见 https://arxiv.org/pdf/1712.05884.pdf

这篇文章主要包含两部分：
- text到mel谱的预测模型，是基于tacotron的改进
- 从mel谱到波形采用了修改版的WaveNet

文章提到之所以要采用mel谱作为一个中间过度变量，是因为它可以用更低的维度表征声音信息，并且可以加强低频区域的细节（对于speech intelligibility非常重要）。

在tacotron中，计算mel谱的STFT的参数是50ms的frame size，12.5ms的frame hop和一个Hann window function。为了匹配原始的WaveNet的输入频率，我们将frame hop改为了5ms，但是会增加了temporal resolution，带来一些发音问题。

网络仍是基于attention的seq2seq模型。

首先是**encoder**：

输入是512维的character embedding，之后送入了3层的CNN层，每一层的卷积核是5x1，有512个，并接有batch normalization和ReLU。CNN层的最后一层接到一个双向的LSTM，这个LSTM有512个units（每个有256个单元）

正则化：CNN采用了dropout进行正则化，p=0.5；LSTM采用了zoneout进行正则化，p=0.1。

附上tensorflow中卷积层的写法：
```python
import tensorflow as tf


class EncoderConvolutions:
    def __init__(self, is_training, hparams, activation=tf.nn.relu, scope=None):
        super(EncoderConvolutions, self).__init__()
        self.is_training = is_training

        self.kernel_size = hparams.enc_conv_kernel_size
        self.channels = hparams.enc_conv_channels
        self.activation = activation
        self.scope = 'enc_con_layers' if scope is None else scope
        self.drop_rate = hparams.tacotron_drop_rate
        self.enc_conv_num_layers = hparams.enc_conv_num_layers
        self.bnorm = hparams.batch_norm_position
    
    def __call__(self, inputs):
        with tf.variable_scope(self.scope):
            x = inputs
            for i in range(self.enc_conv_num_layers):
                x = conv1d(x, self.kernel_size, self.channels, self.activation,
                           self.is_training, self.drop_rate, self.bnorm, 'conv_layer_{}_'.format(i + 1)+self.scope)
                return x


def conv1d(inputs, kernel_size, channels, activation, is_training, drop_rate, bnorm, scope):
    assert bnorm in ('before', 'after')
    with tf.variable_scope(scope):
        conv1d_output = tf.layers.conv1d(
            inputs,
            filters=channels,
            kernel_size=kernel_size,
            activation=activation if bnorm == 'after' else None,
            padding='same'
        )
        batched = tf.layers.batch_normalization(conv1d_output, training=is_training)
        activated = activation(batched) if bnorm == 'before' else batched
        return tf.layers.dropout(activated, rate=drop_rate, training=is_training,
                                 name='dropout_{}'.format(scope))
```

LSTM层的写法：
```python
import tensorflow as tf


class ZoneoutLSTMCell(tf.nn.rnn_cell.RNNCell):
    def __init__(self, num_units, is_training, zoneout_factor_cell=0., zoneout_factor_output=0., state_is_tuple=True, name=None):
        '''Initializer with possibility to set different zoneout values for cell/hidden states.
        '''
        zm = min(zoneout_factor_output, zoneout_factor_cell)
        zs = max(zoneout_factor_output, zoneout_factor_cell)

        if zm < 0. or zs > 1.:
            raise ValueError('One/both provided Zoneout factors are not in [0, 1]')

        self._cell = tf.nn.rnn_cell.LSTMCell(num_units, state_is_tuple=state_is_tuple, name=name)
        self._zoneout_cell = zoneout_factor_cell
        self._zoneout_outputs = zoneout_factor_output
        self.is_training = is_training
        self.state_is_tuple = state_is_tuple

    @property
    def state_size(self):
        return self._cell.state_size

    @property
    def output_size(self):
        return self._cell.output_size        

    def __call__(self, inputs, state, scope=None):
        '''Runs vanilla LSTM Cell and applies zoneout.
        '''
        #Apply vanilla LSTM
        output, new_state = self._cell(inputs, state, scope)

        if self.state_is_tuple:
            (prev_c, prev_h) = state
            (new_c, new_h) = new_state
        else:
            num_proj = self._cell._num_units if self._cell._num_proj is None else self._cell._num_proj
            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])
            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])
            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])
            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])

        #Apply zoneout
        if self.is_training:
            #nn.dropout takes keep_prob (probability to keep activations) not drop_prob (probability to mask activations)!
            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c, (1 - self._zoneout_cell)) + prev_c
            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h, (1 - self._zoneout_outputs)) + prev_h

        else:
            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c
            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h

        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c, h])

        return output, new_state


class EncoderRNN:
    def __init__(self, is_training, size=256, zoneout=0.1, scope=None):
        super(EncoderRNN, self).__init__()
        self.is_training = is_training
        self.size = size
        self.zoneout = zoneout
        self.scope = 'encoder_LSTM' if scope is None else scope

        self._fw_cell = ZoneoutLSTMCell(size,
                                        is_training,
                                        zoneout_factor_cell=zoneout,
                                        zoneout_factor_output=zoneout,
                                        name='encoder_fw_LSTM')

        self._bw_cell = ZoneoutLSTMCell(size, 
                                        is_training,
                                        zoneout_factor_cell=zoneout,
                                        zoneout_factor_output=zoneout,
                                        name='encoder_bw_LSTM')

    def __call__(self, inputs, input_lengths):
        with tf.variable_scope(self.scope):
            outputs, (fw_state, bw_state) = tf.nn.bidirectional_dynamic_rnn(
                self._fw_cell,
                self._bw_cell,
                inputs,
                sequence_length=input_lengths,
                dtype=tf.float32,
                swap_memory=True
            )
        return tf.concat(outputs, axis=2)
```

**attention**

这里采用的是location sensitive attention，具体在attention一文中讲到过，这种attention是基于additive attention做的改进，引入了上一时间步累积attention权重。这种方式有助于模型的attention在input上面连续前进，减少了一些可能的失败，如一些序列被重复了或者被忽视了。最新版本的tacotron里面的attention在合成的时候，可以加入synthesis_constraint。

具体而言，synthesis_constraint是指在做inference的时候，根据上一时刻的最大的attention对当前的attention加一些约束，使得当前时刻attention是跟上一时刻attention相关的，这样更容易对齐。

有两种constraint的方式：
- monotonic, 直接在上一次的max_attention的位置，往后移动attention_win_size个位置，只取这个区间内计算得到的alignment score，其他区间都设置为-2 ** 32 + 1
- window, 以上一次的max_attention的位置为中心，取attention_win_size个位置，只取这个区间内计算的

```python
import tensorflow as tf

energy = _location_sensitive_score(processed_query, processed_location_features, self.keys) # alignment score [batch_size, max_time]

Tx = tf.shape(energy)[-1]
if self.constraint_type == 'monotinic':
    key_masks = tf.sequence_mask(prev_max_attentions, Tx)
    # -  -  -  -  -  -  max  -  -  -  -
    # T  T  T  T  T  T   T   F  F  F  F
    reverse_masks = tf.sequence_mask(Tx - self.attention_win_size - prev_max_attentions, Tx)[:, ::-1]
    # attention_win_size = 2
    # -  -  -  -  -  -  max  -  -  -  -
    # F  -  -  -  -  F   F   F  F  T  T
else:
    assert self.constraint_type == 'window'
    key_masks = tf.sequence_mask(prev_mask_attentions - (self.attention_win_size // 2 + (self.attention_win_size % 2 != 0)), Tx)
    # attention_win_size = 4
    # -  -  -  -  -  -  max  -  -  -  -
    # T  T  T  T  T  F   F   F  F  F  F
    reverse_masks = tf.sequence_mask(Tx - (self.attention_win_size // 2) - prev_max_attentions, Tx)[:, ::-1]
    # -  -  -  -  -  -  max  -  -  -  -
    # F  F  F  F  F  F   F   F  F  T  T

masks = tf.logical_or(key_masks, reverse_masks)
paddings = tf.ones_like(energy) * (-2 ** 32 + 1) 
energy = tf.where(tf.equal(mask, False), energy, paddings)
```


**decoder**

前一时间步的prediction显示要送入一个prenet。这个prenet包含两层全连接，每层256channel，激活函数为ReLU。prenet起到了一个bottleneck的作用，这对于学习attention是非常重要的。
prenet的输出和context vecotr拼起来，再送入两层的单向LSTM，每层1024units。LSTM的输出和context vector拼起来，再送入到一个线性层，预测目标mel谱。最后，预测得到的mel谱再送入一个5层CNN的postnet，作为一个residual层，输出加到了前面的预测结果上，来提高整体的重建程度。每层postnet都包含有512个滤波器，核为5x1,含有normalization，除了最后一层都连接有tanh激活函数。另外，decoder LSTM的输出和attention context还concat一起，经过一层线性层和一层sigmoid层，来预测序列是否应该停止。decoder中的CNN层也需要用dropout来优化，LSTM用zoneout来优化。

prenet的代码很简单，需要注意的是，为了提高输出的多样性，prenet在做inference的时候，仍然用p=0.5的dropout:

```python
for i, size in enumerate(self.layers_sizes):
    dense = tf.layers.dense(x, units=size, activation=self.activation)
    x = tf.layers.dropout(dense, rate=self.drop_date, training=True)
```

2层单向LSTM的代码：
```python
import tensorflow as tf


class DecoderRNN:
    def __init__(self, is_training, layers=2, size=1024, zoneout=0.1, scope=None):
        super(DecoderRNN, self).__init__()
        self.is_training = is_training
        self.layers = layers
        self.size = size
        self.zoneout = zoneout
        self.scope = 'decoder_rnn' if scope is None else scope

        # create a set of LSTM layers
        self.rnn_layers = [ZoneoutLSTMCell(size, 
                                           is_training,
                                           zoneout_factor_cell=zoneout,
                                           zoneout_factor_output=zoneout,
                                           name='decoder_LSTM_{}'.format(i+1)) for i in range(layers)]
        
        self._cell = tf.contrib.rnn.MultiRNNCell(self.rnn_layers, state_is_tuple=True)
    
    def __call__(self, inputs, states):
        with tf.variable_scope(self.scope):
            return self._cell(inputs, states)
```

最后的线性层非常简单，只是一层全连接.

stopnet的代码
```python
import tensorflow as tf


class StopProjection:
    def __init__(self, is_training, shape=1, activation=tf.nn.sigmoid, scope=None):
        super(StopProjection, self).__init__()
        self.is_training = is_training
        self.shape = shape
        self.activation = activation
        self.scope = 'stop_token_projection' if scope is None else scope
    
    def __call__(self, inputs):
        with tf.varialbe_scope(self.scope):
            output = tf.layers.dense(inputs, units=self.shape, activation=None, name='projection_{}'.format(self.scope))
        
        if self.is_training:
            return output
        return self.activation(output)
```

如何把这几层放在一起呢？定义一个TacotronDecoderCell类,类里面的__call__方法实现的是decoder每一个时间步的解码过程。
```python
import tensorflow as tf
from tensorflow.contrib.rnn import RNNCell
from tensorflow.python.framework import ops, tensor_shape
from tensorflow.python.ops import array_ops, check_ops, rnn_cell_impl, tensor_array_ops, math_ops
from tensorflow.python.util import nest

_zero_state_tensors = rnn_cell_impl._zero_state_tensors


def _compute_attention(attention_mechanism, cell_output, attention_state, attention_layer, prev_max_attentions):
    alignments, next_attention_state, max_attentions = attention_mechanism(
        cell_output, state=attention_state, prev_max_attentions=prev_max_attentions
    )
    expanded_alignments = array_ops.expand_dims(alignments, 1)
    # alignments shape is [batch_size, 1, memory_time]
    # attention_mechanism.value shape is [batch_size, memory_time, memory_size]
    # the batched matmul is over memory_time, so the output shape is [batch_size, 1, memory_size]
    context = math_ops.matmul(expanded_alignments, attention_mechanism.values)
    context = array_ops.squeeze(context, [1])

    if attention_layer is not None:
        attention = attention_layer(array_ops.concat([cell_output, context], 1))
    else:
        attention = context

    return attention, alignments, next_attention_state, max_attentions


class TacotronDecoderCell(RNNCell):
    def __init__(self, prenet, attention_mechanism, rnn_cell, frame_projection, stop_projection):
        super(TacotronDecoderCell, self).__init__()
        self._prenet = prenet
        self._attention_mechanism = attention_mechanism
        self._cell = rnn_cell
        self._frame_projection = frame_projection
        self._stop_projection = stop_projection
        self._attention_layer_size = self._attention_mechanism.values.get_shape()[-1].value

    def _batch_size_checks(self, batch_size, error_message):
        return [check_ops.assert_equal(batch_size,
                                       self._attention_mechanism.batch_size,
                                       message=error_message)]
    
    @property
    def output_size(self):
        return self._frame_projection.shape
    
    @property
    def state_size(self):
        return TacotronDecoderCellState(
            cell_state=self._cell._cell.state_size,
            time=tensor_shape.TensorShape([]),
            attention=self._attention_layer_size,
            alignments=self._attention_mechanism.alignments_size,
            alignment_history=(),
            max_attentions=())
    
    def zero_state(self, batch_size, dtype):
        """Return an initial (zero) state tuple for this AttentionWrapper."""

        with ops.name_scope(type(self).__name__ + 'ZeroState', values=[batch_size]):
            cell_state = self._cell._cell.zero_state(batch_size, dtype)
            error_message = (
                "When calling zero_state of TacotronDecoderCell %s: " % self._base_name +
                "Non-matching batch sizes between the memory "
                "(encoder output) and the requested batch size."
            )
            with ops.control_dependencies(
                self._batch_size_checks(batch_size, error_message)
            ):
                cell_state = nest.map_structure(
                    lambda s: array_ops.identity(s, name='checked_cell_state'),
                    cell_state
                )
            return TacotronDecoderCellState(
                cell_state=cell_state,
                time=array_ops.zeros([], dtype=tf.int32),
                attention=_zero_state_tensors(self._attention_layer_size, batch_size, dtype),
                alignments=self._attention_mechanism.initial_alignments(batch_size, dtype),
                alignment_history=tensor_array_ops.TensorArray(dtype=dtype, size=0, dynamic_size=True),
                max_attentions=tf.zeros((batch_size, ), dtype=tf.int32)
            )

    def __call__(self, inputs, state):
        prenet_output = self._prenet(inputs)
        LSTM_input = tf.concat([prenet_output, state.attention], axis=-1)
        LSTM_output, next_cell_state = self._cell(LSTM_input, state.cell_state)

        # compute the attention (context) vector and alignments using the new decoder cell hidden state
        # as query vector and cumulative alignments to extract location features
        # The choice if the new cell hidden state (s_i) of the last decoder RNN cell is based on Luong et Al.
        previous_alignments = state.alignments
        previous_alignment_history = state.alignment_history
        context_vector, alignments, cumulated_alignments, max_attentions = _compute_attention(self._attention_mechanism,
            LSTM_output,
            previous_alignments,
            attention_layer=None,
            prev_max_attentions=state.max_attentions)

        # Concat LSTM output and context vector to for projections inputs
        projections_input = tf.concat([LSTM_output, context_vector], axis=-1)

        cell_outputs = self._frame_projection(projections_input)
        stop_tokens = self._stop_projection(projections_input)

        alignment_history = previous_alignment_history.write(state.time, alignments)

        next_state = TacotronDecoderCellState(
            time=state.time+1,
            cell_state=next_cell_state,
            attention=context_vector,
            alignments=cumulated_alignments,
            alignment_history=alignment_history,
            max_attentions=max_attentions
        )

        return (cell_outputs, stop_tokens), next_state

decoder_cell = TacotronDecoderCell(
    prenet,
    attention_mechanism,
    decoder_lstm,
    frame_projection,
    stop_projection
)
```

之后就可以利用dynamic_decode进行解码了，dynamic_decoder的输入需要是一个decoder，因此还要定义一个CustomDecoder， 继承decoder.Decoder。注意，需要在training和inference阶段分别定义一个helper
```python
from tensorflow.contrib.seq2seq.python.ops import decoder
from tensorflow.contrib.seq2seq import dynamic_decode


class CustomDecoder(decoder.Decoder):
    def __init__(self, cell, helper, initial_state, output_layer=None):
        self._cell = cell
        self._helper = helper
        self._initial_state = initial_state
        self._output_layer = output_layer
    
    def initialize(self, name=None):
        return self._helper.initialize() + (self._initial_state,)
    
    def step(self, time, inputs, state, name=None):
        with ops.name_scope(name, 'CustomDecoderStep', (time, inputs, state)):
            (cell_outputs, stop_token), cell_state = self._cell(inputs, state)

            if self._output_layer is not None:
                cell_outputs = self._output_layer(cell_outputs)
            sample_ids = self._helper.sample(
                time=time, outputs=cell_outputs, state=cell_state
            )

            (finished, next_inputs, next_state) = self._helper.next_inputs(
                time=time,
                outputs=cell_outputs,
                state=cell_state,
                sample_ids=sample_ids,
                stop_token_prediction=stop_token
            )
        outputs = CustomDecoderOutput(cell_outputs, stop_token, sample_ids)
        return (outputs, next_state, next_inputs, finished)


(frames_projection, stop_token_prediction, _), final_decoder_state, _ = dynamic_decode(
    CustomDecoder(decoder_cell, self._helper, decoder_init_state),
    impute_finished=False,
    maximum_iterations=max_iters,
    swap_memory=hp.tacotron_swap_with_cpu
)
```

前面讲过，decoder会生成mel谱，不过还需要再创建一个postnet,接受这个mel谱，并生成新的mel谱，这里的postnet起到一个residual的作用.代码如下：

```python
import tensorflow as tf


class Postnet:
    def __init__(self, is_training, hparams, activation=tf.nn.tanh, scope=None):
        super(Postnet, self).__init__()
        self.is_training = is_training
        self.kernel_size = hparams.postnet_kernel_size
        self.channels = hparams.channels
        self.activation = activation
        self.scope = 'postnet_convolutions' if scope is None else scope
        self.postnet_num_layers = hparams.postnet_num_layers
        self.drop_rate = hparams.tacotron_dropout_rate
        self.bnorm = hparams.batch_norm_position
    
    def __call__(self, inputs):
        with tf.variable_scope(self.scope):
            x = inputs
            for i in range(self.postnet_num_layers):
                x = conv1d(x, self.kernel_size, self.channels, self.activation,
                           self.is_training, self.drop_rate, self.bnorm, 'conv_layer_{}_'.format(i+1)+self.scope)
            x = conv1d(x, self.kernel_size, self.channels, lambda _: _, self.is_training, self.drop_rate, self.bnorm,
                       'conv_layer_{}_'.format(5)+self.scope)
        return x


class FrameProjection:
    """ Projection layer to r * num_mels dimensions or num_mels dimensions."""
    def __init__(self, shape=80, activation=None, scope=None):
        super(FrameProjection, self).__init__()
        self.shape = shape
        self.activation = activation
        self.scope = 'linear_projection' if scope is None else scope
        self.dense = tf.layers.Dense(units=shape, activation=activation, name='projection_{}'.format(self.scope))
    
    def __call__(self, inputs):
        with tf.variable_scope(self.scope):
            outputs = self.dense(inputs)
            return outputs


# Reshape outputs to be one output per entry
# ==> [batch_size, non_reduced_decoder_steps (decoder_steps * r), num_mels]
decoder_output = tf.reshape(frames_prediction, [batch_size, -1, hp.num_mels])

postnet = Postnet(is_training, hparams=hp, scope='postnet_convolutions')

residual = postnet(decoder_output)

residual_projection = FrameProjection(hp.num_mels, scope='postnet_projection')
projected_residual = residual_projection(residual)

mel_outputs = decoder_output + projected_residual
```

需要注意的是，计算mel谱的loss的时候，需要计算postnet之前和之后的两个loss，来帮助收敛．
如果用griffin-lim的话，需要加一个mel谱到线性谱的预测网络．和tacotron1一样是用CBHG的．