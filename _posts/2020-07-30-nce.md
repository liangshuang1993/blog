#### Noise-contrastive estimation: A new estimation principle for unnormalized statistical models 
噪声对比估计

自然语言处理中， 在计算某个单词的概率的时候，需要用softmax计算，因而需要用到整个字典的单词，当字典很大时，这个softmax的计算量非常大，不容易计算。

定义一个随机向量$x \in R^n$ 服从一个未知分布$p_d(.)$, 一个parametrized family of functions ${p_m(.;\alpha)}_{\alpha}$来对其建模。根据概率密度函数的性质，可以知道

$$\int p_m(u;\hat \alpha) du =1$$

也可以写作

$$p_m(,;\alpha) = \frac{p^0_m(,;\alpha)}{Z(\alpha)}, Z(\alpha) = \int p^0_m(u;\alpha)du$$

计算$Z(\alpha)$ 通常比较困难。这篇文章利用最大化同一个目标函数来估计 $\alpha$  和 $Z$。

### 定义

将归一化常数作为模型的另一个参数c. 定义 $ln~p_m(,;\theta) = ln~p^0_m(,;\theta) + c$. 其中$\theta=\{\alpha, c\}$,只有当c取某些特定值的时候，$p_m(,;\theta)$才能积分为1.

定义$X=(x_1, ..., x_T)$是观测到的数据集。$Y=(y_1, ..., y_T)$是由分布$p_n(.)$生成的噪音数据。 最大化下式可以得到$\hat\theta_T$.

$$J_T(\theta) = \frac{1}{2*T}\sum_t \ln[h(x_t; \theta)] + \ln[1-h(y_t; \theta)]$$， 其中

$$h(u; \theta) = \frac{1}{1 + exp[-G(u;\theta)]}$$
$$G(u; \theta) = \ln p_m(u;\theta) - \ln p_n(u)$$

上式其实是一个逻辑回归log-likelihood。

####推导过程

将集合X和Y的比U并集记作$U=(u_1, u_2, ..., u_{2T})$,给里面每个样本都指定一个标签$C_t$, 如果$u_t$是集合X中的，那么$C_t=1$, 如果$u_t$是集合Y中的，那么$C_t=0$




可以得到

$$p(u|C=1;\theta) = p_m(u;\theta)$$
$$p(u|C=0;\theta) = p_n(u)$$

又由于X和Y中的样本一样多，所以$P(C=1) = P(C=0) = 1/2$

因此可以得到    

$$ P(C=1|u;\theta) = \frac{p_m(u;\theta)}{p_m(u;\theta) + p_n(u)} = h(u; \theta) $$
$$ P(C=0|u;\theta) = 1 - h(u;\theta) $$


$C_t$是伯努利分布，因此log-likelihood为：

$$l(\theta) = \sum_t C_t lnP(C_t=1|u_t; \theta) + (1-C_t) ln(C_t=0|u_t; \theta) = \sum_t ln[h(x_t; \theta)] + ln[1 - h(y_t; \theta)]$$





##### properties of the estimator

当T足够大的时候，可以得到

$$J(\theta) = \frac{1}{2} E ln[h(x;\theta)] + ln[1 - h(y;\theta)]$$

定义$\tilde J$作为一个关于$f=lnp_m(,;\theta)$的函数

$$\tilde J(f) = \frac{1}{2} E ln[r(f(x) - lnp_n(x))] + ln[1 - r(f(y) - lnp_n(y))]$$




直接带入得到

$$\tilde J(f) = \frac{1}{2} ln[r(f(x) - ln p_n(x))] + ln [1 - r(f(y) - ln p_n(y))]$$


**定理1 非参数估计 $\widetilde{J}$在$f_m=\ln{p_d}$时达到最大。噪声密度函数$p_n$一旦确定，$\widetilde{J}$的最大值也就唯一确定，$p_n$在$p_d$取值大于零的地方也大于零。**

证明：


记$p_{m_i}$为$\theta$参数下产生的样本的概率密度函数

样本的联合概率密度分布为

$$e^{l(\theta)} = \prod_i (\frac{p_m}{p_m + p_n}) ^ {p_d} * (\frac{p_n}{p_m + p_n}) ^ {p_n}$$

$$l(\theta) = \sum_i p_d \ln (\frac{p_m}{p_m + p_n}) + p_n \ln (\frac{p_n}{p_m + p_n})$$

对$p_m$求导可得

$p_m = p_d$时l取极值


